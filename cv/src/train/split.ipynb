{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f03e23-bbb4-4ecc-a663-9416ce546025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To split dataset in 70% training, 20% val, 10% test\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "base_path = Path(\"/home/jupyter/tilai-bjjsql/cv/src/train\")\n",
    "images_path = base_path / \"images\"\n",
    "labels_path = base_path / \"labels\"\n",
    "\n",
    "# Output paths\n",
    "split_path = base_path / \"split\"\n",
    "splits = {\n",
    "    \"train\": 0.7,\n",
    "    \"val\": 0.2,\n",
    "    \"test\": 0.1\n",
    "}\n",
    "\n",
    "# Create output folders\n",
    "for split in splits:\n",
    "    for subdir in [\"images\", \"labels\"]:\n",
    "        (split_path / split / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get list of all image files\n",
    "image_files = list(images_path.glob(\"*.jpg\"))\n",
    "random.seed(42)\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Calculate split indices\n",
    "n = len(image_files)\n",
    "n_train = int(n * splits[\"train\"])\n",
    "n_val = int(n * splits[\"val\"])\n",
    "\n",
    "train_files = image_files[:n_train]\n",
    "val_files = image_files[n_train:n_train + n_val]\n",
    "test_files = image_files[n_train + n_val:]\n",
    "\n",
    "def copy_pair(image_file, target_image_dir, target_label_dir):\n",
    "    label_file = labels_path / (image_file.stem + \".txt\")\n",
    "    if label_file.exists():\n",
    "        shutil.copy(image_file, target_image_dir / image_file.name)\n",
    "        shutil.copy(label_file, target_label_dir / label_file.name)\n",
    "\n",
    "# Copy files\n",
    "for f in train_files:\n",
    "    copy_pair(f, split_path / \"train\" / \"images\", split_path / \"train\" / \"labels\")\n",
    "for f in val_files:\n",
    "    copy_pair(f, split_path / \"val\" / \"images\", split_path / \"val\" / \"labels\")\n",
    "for f in test_files:\n",
    "    copy_pair(f, split_path / \"test\" / \"images\", split_path / \"test\" / \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd889a9-3dbf-4fa5-a4bd-615fe4bbc971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split dataset in 80% training, 20% val\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "base_path = Path(\"/home/jupyter/tilai-bjjsql/cv/src/train\")\n",
    "images_path = base_path / \"images\"\n",
    "labels_path = base_path / \"labels\"\n",
    "\n",
    "# Output paths\n",
    "split_path = base_path / \"v1_split\"\n",
    "splits = {\n",
    "    \"train\": 0.8,\n",
    "    \"val\": 0.2\n",
    "}\n",
    "\n",
    "# Create output folders\n",
    "for split in splits:\n",
    "    for subdir in [\"images\", \"labels\"]:\n",
    "        (split_path / split / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get list of all image files\n",
    "image_files = list(images_path.glob(\"*.jpg\"))\n",
    "random.seed(42)\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Calculate split indices\n",
    "n = len(image_files)\n",
    "n_train = int(n * splits[\"train\"])\n",
    "\n",
    "train_files = image_files[:n_train]\n",
    "val_files = image_files[n_train:]\n",
    "\n",
    "def copy_pair(image_file, target_image_dir, target_label_dir):\n",
    "    label_file = labels_path / (image_file.stem + \".txt\")\n",
    "    if label_file.exists():\n",
    "        shutil.copy(image_file, target_image_dir / image_file.name)\n",
    "        shutil.copy(label_file, target_label_dir / label_file.name)\n",
    "\n",
    "# Copy files\n",
    "for f in train_files:\n",
    "    copy_pair(f, split_path / \"train\" / \"images\", split_path / \"train\" / \"labels\")\n",
    "for f in val_files:\n",
    "    copy_pair(f, split_path / \"val\" / \"images\", split_path / \"val\" / \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfabbcf-bdcd-40dd-90e1-6d9aac13f2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying to v2_split/train/images: 100%|██████████| 16000/16000 [26:11<00:00, 10.18it/s]\n",
      "Copying to v2_split/valid/images: 100%|██████████| 4000/4000 [06:42<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done! Dataset split into:\n",
      "- Train: 16000 images → v2_split/train/images\n",
      "- Valid: 4000 images → v2_split/valid/images\n"
     ]
    }
   ],
   "source": [
    "# v2: For DEIM, split 80% training 20% val, \n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "SOURCE_IMAGES_DIR = \"../../../../novice/cv/images\"\n",
    "ANNOTATIONS_PATH = \"../../../../novice/cv/annotations.json\"\n",
    "OUTPUT_BASE = Path(\"v2_split\")  # local to current notebook folder\n",
    "TRAIN_RATIO = 0.8\n",
    "random.seed(42)\n",
    "\n",
    "# === DESTINATION FOLDERS ===\n",
    "train_images_dir = OUTPUT_BASE / \"train/images\"\n",
    "valid_images_dir = OUTPUT_BASE / \"valid/images\"\n",
    "train_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "valid_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === LOAD ANNOTATIONS ===\n",
    "with open(ANNOTATIONS_PATH, \"r\") as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "images = coco[\"images\"]\n",
    "annotations = coco[\"annotations\"]\n",
    "categories = coco[\"categories\"]\n",
    "\n",
    "# === SPLIT IMAGES ===\n",
    "random.shuffle(images)\n",
    "num_train = int(len(images) * TRAIN_RATIO)\n",
    "train_images = images[:num_train]\n",
    "valid_images = images[num_train:]\n",
    "\n",
    "# === FILTER ANNOTATIONS ===\n",
    "def filter_annotations(image_subset):\n",
    "    image_ids = {img[\"id\"] for img in image_subset}\n",
    "    return [anno for anno in annotations if anno[\"image_id\"] in image_ids]\n",
    "\n",
    "train_annos = filter_annotations(train_images)\n",
    "valid_annos = filter_annotations(valid_images)\n",
    "\n",
    "# === COPY IMAGES ===\n",
    "def copy_images(image_subset, dest_dir):\n",
    "    for img in tqdm(image_subset, desc=f\"Copying to {dest_dir}\"):\n",
    "        src = Path(SOURCE_IMAGES_DIR) / img[\"file_name\"]\n",
    "        dst = Path(dest_dir) / img[\"file_name\"]\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "copy_images(train_images, train_images_dir)\n",
    "copy_images(valid_images, valid_images_dir)\n",
    "\n",
    "# === SAVE SPLIT ANNOTATIONS ===\n",
    "def save_annotations(image_subset, anno_subset, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"images\": image_subset,\n",
    "            \"annotations\": anno_subset,\n",
    "            \"categories\": categories\n",
    "        }, f, indent=2)\n",
    "\n",
    "save_annotations(train_images, train_annos, OUTPUT_BASE / \"train/_annotations.coco.json\")\n",
    "save_annotations(valid_images, valid_annos, OUTPUT_BASE / \"valid/_annotations.coco.json\")\n",
    "\n",
    "print(\"\\n✅ Done! Dataset split into:\")\n",
    "print(f\"- Train: {len(train_images)} images → {train_images_dir}\")\n",
    "print(f\"- Valid: {len(valid_images)} images → {valid_images_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5208cb5a-2cc5-4263-843a-d3af03c253d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
